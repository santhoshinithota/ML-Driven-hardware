# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17kFoe9FaAgqkcV57ZGXg0drQ0CKwaJba
"""

# def input_fn(features , batch_size = 256):
#     return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)


# features = ['SeptalLength' , 'SeptalWidth' , 'PetalLength' , 'PetalWidth']
# predict = {}

# print("Please type the numeric value as prompted")
# for feature in features:
#     valid=True
#     while valid:
#         val = input(feature + ":")
#         if not val.isdigit(): valid = False

#     predict[feature] = [float(val)]

# predictions = classifier.predict(input_fn=lambda:input_fn(predict))
# for pred_dict in predictions:
#     class_id = pred_dict['class_ids'][0]
#     probability = pred_dict['probabilities'][class_id]
#     print('Prediction is "{}"({:.1f}%)'.format(SPECIES[class_id] , 100 * probability))

# Commented out IPython magic to ensure Python compatibility.
from __future__ import absolute_import , division , print_function , unicode_literals
!pip install -q sklearn

# %tensorflow_version 2.x
from google.colab import drive

drive.mount('/content/drive',force_remount = True)
import os
import sys
import sklearn as sk
import  pandas as pd
import matplotlib.pyplot as plot
import tensorflow.compat.v2.feature_column as fc
import tensorflow as tf
from IPython.display import clear_output
from six.moves import urllib
from sklearn.metrics import mean_squared_error

dftrain = pd.read_csv('/content/1.csv')
dfeval = pd.read_csv('/content/values.csv')
y_train = dftrain.pop('Frequency')
y_eval = dfeval.pop('Frequency')
# print(y_eval)
# print(dftrain)
# print(y_train)
CATEGORICAL_COLUMNS = ['Serial']
NUMERICAL_COLUMNS = ['Voltage']

feature_columns = []

for feature_name in CATEGORICAL_COLUMNS:
    vocabulary = dftrain[feature_name].unique()
    feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name , vocabulary))

print(feature_columns)

for feature_name in NUMERICAL_COLUMNS:
    feature_columns.append(tf.feature_column.numeric_column(feature_name , dtype=tf.float32))

def make_input_function(data_df , label_df , num_epachs=1000, shuffle=True , batch_size=25):
    def input_function():
        ds = tf.data.Dataset.from_tensor_slices((dict(data_df) , label_df))
        if shuffle:
            ds = ds.shuffle(1000)
        ds = ds.batch(batch_size).repeat(num_epachs)
        return ds
    return input_function

train_input_fn = make_input_function(dftrain,y_train)
eval_input_fn = make_input_function(dfeval , y_eval , num_epachs=1 , shuffle=False)

linear_est = tf.estimator.LinearRegressor(feature_columns=feature_columns)
linear_est.train(train_input_fn)
result = linear_est.evaluate(eval_input_fn)

clear_output()

# print(result['accuracy'])

# print(result)
result = list(linear_est.predict(eval_input_fn))
print(result)
# result = tuple(result)
p = []

# for i in range(len(result)) :
#   array = result[i]['predictions']
#   p.append(array[0])
# # print(mean_squared_error(y_eval.values, result.values))
# ### Mean square error
# mean_squared_error(y_eval,p)

# print(dfeval.loc[2])
# print(y_eval.loc[2])
# print(result[0]['predictions'][0])

# from __future__ import absolute_import , division , print_function , unicode_literals
# !pip install -q sklearn

# %tensorflow_version 2.x

# import sklearn as sk
# import  pandas as pd
# import matplotlib.pyplot as plot
# import tensorflow.compat.v2.feature_column as fc
# import tensorflow as tf
# from IPython.display import clear_output
# from six.moves import urllib

# CSV_COLUMNS_NAMES = ['Frequency' , 'Voltage']
# # SPECIES = ['Setosa' , 'Versicolor' , 'Virginica']

# train_path = tf.keras.utils.get_file("iris_training.csv" , "https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv")
# test_path = tf.keras.utils.get_file("iris_test.csv" , "https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv")

# train = pd.read_csv(train_path , names=CSV_COLUMNS_NAMES , header = 0)
# test = pd.read_csv(test_path , names=CSV_COLUMNS_NAMES , header = 0)

# train_y = train.pop('Frequency')
# test_y = test.pop('Frequency')

# def input_fn(features , labels , training=True , batch_size = 256):
#     dataset = tf.data.Dataset.from_tensor_slices((dict(features) , labels))
#     if training:
#         dataset = dataset.shuffle(1000).repeat()
#     return dataset.batch(batch_size)

# my_feature_columns = []
# for key in train.keys():
#     my_feature_columns.append(tf.feature_column.numeric_column(key=key))

# classifier = tf.estimator.DNNClassifier(
#     feature_columns=my_feature_columns,
#     hidden_units = [30, 10],
#     n_classes=3)

# classifier.train(input_fn = lambda: input_fn(train , train_y , training=True),
#                  steps=5000)

# eval_result = classifier.evaluate(input_fn=lambda: input_fn(test , test_y , training=False))
# print("\nTest set accuracy: {accuracy:0.3f}\n".format(**eval_result))

# def input_fn(features , batch_size = 256):
#     return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)


# features = ['SeptalLength' , 'SeptalWidth' , 'PetalLength' , 'PetalWidth']
# predict = {}

# print("Please type the numeric value as prompted")
# for feature in features:
#     valid=True
#     while valid:
#         val = input(feature + ":")
#         if not val.isdigit(): valid = False

#     predict[feature] = [float(val)]

# predictions = classifier.predict(input_fn=lambda:input_fn(predict))
# for pred_dict in predictions:
#     class_id = pred_dict['class_ids'][0]
#     probability = pred_dict['probabilities'][class_id]
#     print('Prediction is "{}"({:.1f}%)'.format(SPECIES[class_id] , 100 * probability))

# from __future__ import absolute_import , division , print_function , unicode_literals
# !pip install -q sklearn

# %tensorflow_version 2.x

# import sklearn as sk
# import  pandas as pd
# import matplotlib.pyplot as plot
# import tensorflow.compat.v2.feature_column as fc
# import tensorflow as tf
# from IPython.display import clear_output
# from six.moves import urllib

# CSV_COLUMNS_NAMES = ['SeptalLength' , 'SeptalWidth' , 'PetalLength' , 'PetalWidth' , 'Species']
# SPECIES = ['Setosa' , 'Versicolor' , 'Virginica']

# train_path = tf.keras.utils.get_file("iris_training.csv" , "https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv")
# test_path = tf.keras.utils.get_file("iris_test.csv" , "https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv")

# train = pd.read_csv(train_path , names=CSV_COLUMNS_NAMES , header = 0)
# test = pd.read_csv(test_path , names=CSV_COLUMNS_NAMES , header = 0)

# train_y = train.pop('Species')
# test_y = test.pop('Species')

# def input_fn(features , labels , training=True , batch_size = 256):
#     dataset = tf.data.Dataset.from_tensor_slices((dict(features) , labels))
#     if training:
#         dataset = dataset.shuffle(1000).repeat()
#     return dataset.batch(batch_size)

# my_feature_columns = []
# for key in train.keys():
#     my_feature_columns.append(tf.feature_column.numeric_column(key=key))

# classifier = tf.estimator.DNNClassifier(
#     feature_columns=my_feature_columns,
#     hidden_units = [30, 10],
#     n_classes=3)

# classifier.train(input_fn = lambda: input_fn(train , train_y , training=True),
#                  steps=5000)

# eval_result = classifier.evaluate(input_fn=lambda: input_fn(test , test_y , training=False))
# print("\nTest set accuracy: {accuracy:0.3f}\n".format(**eval_result))